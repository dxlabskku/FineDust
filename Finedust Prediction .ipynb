{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88dcf722",
   "metadata": {},
   "source": [
    "# load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f7e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefiler(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from haversine import haversine\n",
    "import googlemaps\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from math import sqrt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4edf99b",
   "metadata": {},
   "source": [
    "# load meta data and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99547013",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_meta = pd.read_csv('/content/drive/MyDrive/미세먼지/AIR/air_location.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c74003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(year):\n",
    "    meta_all = pd.read_csv('META/meta_all.csv')\n",
    "    asos = pd.read_csv('ASOS_2012-2020/ASOS_%d.csv' % (year), encoding='cp949')\n",
    "    aws = pd.read_csv('AWS_2012-2020/AWS_%d.csv' % (year), encoding='utf-8')\n",
    "    globals()['{}_{}'.format('concat', year)] = pd.concat([asos,aws], axis=0)\n",
    "    final_concat = pd.merge(globals()['concat_{}'.format(year)], meta_all, on='지점', how='left')\n",
    "    final_concat.to_csv('weather_2012-2020/weather_{}.csv'.format(year), index=False)\n",
    "    print('{} shape'.format(year), final_concat.shape)\n",
    "    print(final_concat.위도.isnull().sum())\n",
    "\n",
    "for year in range(2012,2021):\n",
    "    merge_data(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36e1525",
   "metadata": {},
   "source": [
    "## format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f23ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_all['위도'] = meta_all['위도'].astype('float')\n",
    "meta_all['경도'] = meta_all['경도'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379e6cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_asos = pd.read_csv('META_관측지점정보_ASOS.csv',encoding = 'cp949')\n",
    "meta_aws = pd.read_csv('META_관측지점정보_AWS.csv',encoding = 'cp949')\n",
    "\n",
    "wrong_loc = [565,567,599,646,670,932]\n",
    "\n",
    "meta_aws.drop(columns = ['기압계(관측장비지상높이(m))', '기온계(관측장비지상높이(m))', \n",
    "                         '풍속계(관측장비지상높이(m))','강우계(관측장비지상높이(m))'],inplace = True)\n",
    "\n",
    "aws_arr = meta_aws.values\n",
    "\n",
    "for i in range(len(aws_arr)):\n",
    "    if aws_arr[i,0] in wrong_loc:\n",
    "        aws_arr[i,6] = aws_arr[i,7]\n",
    "        aws_arr[i,7] = aws_arr[i,8]\n",
    "\n",
    "meta_aws2 = pd.DataFrame(aws_arr, columns = ['지점', '시작일', '종료일', '지점명', '지점주소', '관리관서', '위도', '경도', '노장해발고도(m)'])\n",
    "meta_aws2.info()\n",
    "meta_aws2.drop(columns = ['노장해발고도(m)'], inplace = True )\n",
    "\n",
    "# ASOS 종료된 관측소 삭제\n",
    "is_due = meta_asos[meta_asos['종료일'].isnull() == False]\n",
    "is_due['year'] = is_due['종료일'].apply(lambda x : int(x[:4]))\n",
    "is_due = is_due[is_due['year'] < 2014]\n",
    "due_idx = is_due.index.to_list()\n",
    "meta_asos.drop(due_idx,axis = 0,inplace = True)\n",
    "meta_asos.reset_index(drop=True, inplace=True)\n",
    "\n",
    "is_due = meta_aws[meta_aws['종료일'].isnull() == False]\n",
    "is_due['year'] = is_due['종료일'].apply(lambda x : int(x[:4]))\n",
    "is_due = is_due[is_due['year'] < 2014]\n",
    "due_idx = is_due.index.to_list()\n",
    "meta_aws2.drop(due_idx,axis = 0,inplace = True)\n",
    "meta_aws2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "meta_aws2.drop(['종료일'], axis=1, inplace=True)\n",
    "meta_asos.drop(['종료일'], axis=1, inplace=True)\n",
    "print(meta_aws2.shape, meta_asos.shape)\n",
    "\n",
    "meta_all = pd.concat([meta_aws2,meta_asos], axis=0, ignore_index=True)\n",
    "meta_all.drop_duplicates(['지점'],keep = 'first',inplace = True)\n",
    "meta_all.reset_index(drop=True, inplace=True)\n",
    "\n",
    "meta_all.drop(columns = ['시작일','관리관서','노장해발고도(m)',\n",
    "       '기압계(관측장비지상높이(m))', '기온계(관측장비지상높이(m))', '풍속계(관측장비지상높이(m))',\n",
    "       '강우계(관측장비지상높이(m))'],inplace = True)\n",
    "\n",
    "meta_all.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3550c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_loc(df1, df2):\n",
    "    df1.insert(3,'기상위도',0)\n",
    "    df1.insert(4,'기상경도',0)\n",
    "    \n",
    "    air_arr = df1[['위도','경도']].values\n",
    "    weather_arr = df2[['위도','경도']].values\n",
    "    \n",
    "    for n1 in range(len(air_arr)):\n",
    "        distance = 50000000000 \n",
    "        air_obs = air_arr[n1]\n",
    "    \n",
    "    for n2 in range(len(weather_arr)):\n",
    "        weather_obs = weather_arr[n2]\n",
    "        \n",
    "        ## 거리계산 단위는 km\n",
    "        check = float(haversine(air_obs, weather_obs, unit = 'km'))\n",
    "        \n",
    "        if check < distance:\n",
    "            distance = check\n",
    "            df1.loc[n1,['기상위도','기상경도']] = weather_obs[0], weather_obs[1]\n",
    "            df1.loc[n1,'거리'] = distance\n",
    "\n",
    "  \n",
    "  return df1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e628eb60",
   "metadata": {},
   "source": [
    "## Data mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc_mapping(year):\n",
    "    print('------------ {} ------------'.format(year))\n",
    "    data = pd.read_csv('air_{}.csv'.format(year))\n",
    "    print('mapping전 :', data.shape)\n",
    "    loc = air_location(data)\n",
    "    \n",
    "    print('------------------------')\n",
    "    print('{}년 mapping결과확인'.format(year))\n",
    "    print(loc.isnull().sum())\n",
    "    \n",
    "    air_loc = pd.merge(data,loc,on = ['주소'],how = 'left')\n",
    "    print('------------------------')\n",
    "    print('mapping후 :', air_loc.shape)\n",
    "    \n",
    "    print('------------------------')\n",
    "    print(air_loc[['위도','경도']].isnull().sum())\n",
    "    air_loc.to_csv('AIR_2012-2020/air{}_loc.csv'.format(year), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7bfe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loc = pd.DataFrame(columns = ['주소','위도','경도'])\n",
    "for year in range(2012, 2021):\n",
    "    data = pd.read_csv('air{}_loc.csv'.format(year))\n",
    "    loc = data[['주소','위도','경도']]\n",
    "    \n",
    "    all_loc = pd.concat([all_loc,loc],axis = 0)\n",
    "    \n",
    "    all_loc.drop_duplicates(['주소','위도','경도'],keep='first',inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0fbe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_lat = {75:37.3274259,624:37.5817708,\n",
    "            850: 37.5817708, 869:36.4741724,\n",
    "            963:36.4741724, 998 : 37.1754027,\n",
    "            1102:37.5584719}\n",
    "\n",
    "null_lng = {75:126.9237322, 624:126.863756,\n",
    "            850:126.863756,869:127.25034,\n",
    "            963:127.25034, 998 :  127.0407797,\n",
    "            1102 : 126.5972784}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in null_idx:\n",
    "    all_loc.loc[i,'위도'] = null_lat[i]\n",
    "    all_loc.loc[i,'경도'] = null_lng[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fbdaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loc.to_csv('air_location.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec71d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_location = pd.read_csv('air_location.csv')\n",
    "air_location.drop_duplicates(['위도','경도'],keep = 'first',inplace = True)\n",
    "air_location.reset_index(drop=True, inplace=True)\n",
    "len(air_location)\n",
    "all_loc = pd.read_csv('META/merge_dist.csv')\n",
    "for year in range(2012,2021):\n",
    "    print('------------ {} ------------'.format(year))\n",
    "    data = pd.read_csv('AIR_2012-2020/air_{}.csv'.format(year))\n",
    "    print('mapping전 :', data.shape)\n",
    "    air_loc = pd.merge(data,all_loc,on = ['주소'],how = 'left')\n",
    "    print(air_loc[['위도','경도']].isnull().sum())\n",
    "    print('mapping후 :', data.shape)\n",
    "    air_loc.to_csv('AIR_2012-2020/air_{}_loc.csv'.format(year), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409ee3b",
   "metadata": {},
   "source": [
    "## Air data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c8d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_format(year):\n",
    "    print('------------ {} ------------'.format(year))\n",
    "    df = pd.read_csv('air_{}_loc.csv'.format(year))\n",
    "    shape1 = df.shape\n",
    "    period = len(df.측정일시.unique())\n",
    "    print('start date check({}010101)'.format(year),df.측정일시.unique()[0])\n",
    "    datelist = pd.date_range(datetime(int(year), 1, 1, 1), periods=period, freq='H') # 시작시간, period 확인\n",
    "    a = list(df['측정일시'].unique())\n",
    "    b = list(datelist.strftime(\"%Y-%m-%d %H:%M\"))\n",
    "    print('finally modified date({}-01-01 00:00)'.format(year+1),b[-1])\n",
    "    print('check date:', len(a) == len(b))\n",
    "    date_dic = { original:datetime for original, datetime in zip(a, b) }\n",
    "    df['일시'] = df['측정일시'].apply(lambda x: date_dic[x])    \n",
    "    df.drop(['측정일시'], inplace=True, axis=1)    \n",
    "    shape2 = df.shape\n",
    "    print('check shape:', shape1 == shape2)\n",
    "    df.to_csv('air_{}_loc.csv'.format(year), index=False)\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf2c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2012,2021):\n",
    "    date_format(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f72c9",
   "metadata": {},
   "source": [
    "## Air + Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6bbd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def air_weather_merge(year):\n",
    "    air = pd.read_csv('AIR_2012-2020/air_{}_loc.csv'.format(year))\n",
    "    wea = pd.read_csv('weather_2012-2020/weather_{}.csv'.format(year))\n",
    "    all_ = pd.merge(air,wea, left_on = ['일시', '기상위도', '기상경도'], right_on=['일시', '위도', '경도'], how = 'left')\n",
    "    print('all {} shape:', all_.shape)\n",
    "    all_.to_csv('ALL_2012-2020/all_{}.csv'.format(year), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dd2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2012,2021):\n",
    "    air_weather_merge(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be54c5d0",
   "metadata": {},
   "source": [
    "### drop -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_999(year): # SO2\tCO\tO3\tNO2\tPM10\n",
    "    print('-----------{}-----------'.format(year))\n",
    "    data = pd.read_csv('ALL_2012-2020/all_{}.csv'.format(year))\n",
    "    shape1 = data.shape\n",
    "    data_air = data[['SO2','CO','O3','NO2','PM10']]\n",
    "    drop_index1 = list(data_air[data_air['SO2']< 0].index)\n",
    "    drop_index2 = list(data_air[data_air['CO']< 0].index)\n",
    "    drop_index3 = list(data_air[data_air['O3']< 0].index)\n",
    "    drop_index4 = list(data_air[data_air['NO2']< 0].index)\n",
    "    drop_index5 = list(data_air[data_air['PM10']< 0].index)\n",
    "\n",
    "    drop_index = drop_index1 + drop_index2 + drop_index3 + drop_index4 + drop_index5\n",
    "    drop_index = set(drop_index)\n",
    "    drop_index = list(drop_index)    \n",
    "    \n",
    "    print('삭제된 행 수:',len(drop_index))\n",
    "    data.drop(drop_index, inplace=True)\n",
    "    shape2 = data.shape\n",
    "    print('shape 전후 비교:',shape1, shape2)\n",
    "    data.to_csv('ALL_2012-2020/all_{}_drop.csv'.format(year), index=False)\n",
    "    #return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2012,2021):\n",
    "    drop_999(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b75f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_999_drop(year):\n",
    "    air = pd.read_csv('AIR_2012-2020/air_{}_loc.csv'.format(year))\n",
    "    wea = pd.read_csv('weather_2012-2020/weather_{}.csv'.format(year))\n",
    "    all_ = pd.merge(air,wea, left_on = ['일시', '기상위도', '기상경도'], right_on=['일시', '위도', '경도'], how = 'left')\n",
    "    print('all {} shape:', all_.shape)\n",
    "    all_.to_csv('ALL_2012-2020/all_{}.csv'.format(year), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5dbb32",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc1532",
   "metadata": {},
   "outputs": [],
   "source": [
    "all2014 = pd.read_csv('all_2014.csv')\n",
    "all2015 = pd.read_csv('all_2015.csv')\n",
    "all2016 = pd.read_csv('all_2016.csv')\n",
    "all2017 = pd.read_csv('all_2017.csv')\n",
    "all2018 = pd.read_csv('all_2018.csv')\n",
    "all2019 = pd.read_csv('all_2019.csv')\n",
    "all2020 = pd.read_csv('all_2020.csv')\n",
    "\n",
    "all_data = pd.concat([all2014,all2015,all2016,all2017,all2018,all2019,all2020], axis=0)\n",
    "all_data.to_csv('all_2014-2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24daaf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(year):\n",
    "    #meta_all = pd.read_csv('META/meta_all.csv')\n",
    "    asos = pd.read_csv('ALL_2012-2020/all_%d.csv' % (year))\n",
    "    aws = pd.read_csv('ALL_2012-2020/all_%d.csv' % (year))\n",
    "    globals()['{}_{}'.format('concat', year)] = pd.concat([asos,aws], axis=0)\n",
    "    final_concat = pd.merge(globals()['concat_{}'.format(year)], meta_all, on='지점', how='left')\n",
    "    final_concat.to_csv('weather_2012-2020/weather_{}.csv'.format(year), index=False)\n",
    "    print('{} shape'.format(year), final_concat.shape)\n",
    "    print(final_concat.위도.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033eab87",
   "metadata": {},
   "source": [
    "## Null Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_null(df):\n",
    "    df['지점'] = df['지점'].astype('object')\n",
    "    null_feature = []\n",
    "    for col in df.columns.tolist():\n",
    "        null_count = df[col].isnull().sum()\n",
    "        null_ratio = round(null_count/len(df), 2)*100\n",
    "        if null_ratio >= 50:\n",
    "            null_feature.append(col)\n",
    "        print(col, ' : ', round(null_count/len(df), 2)*100 ,'%' )\n",
    "  \n",
    "    print('----- null_ratio over 50% : -----')\n",
    "    print(null_feature)\n",
    "  \n",
    "    # null 비율이 50%이상인인 변수들은 제거\n",
    "    data = df.drop(columns = null_feature)\n",
    "    return data, null_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, null_feature = find_null(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed65fd58",
   "metadata": {},
   "source": [
    "## Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_out(df):\n",
    "    \n",
    "    feature = [i for i in df.columns.to_list() if df[i].dtype == 'float64']\n",
    "    plt.figure(figsize = (25,15))\n",
    "    for i in range(len(feature)):\n",
    "        h = (len(feature) // 4) + 1\n",
    "        plt.subplot(h,4,i+1)\n",
    "        sns.boxplot(x = feature[i],data = df)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def find_out(df):\n",
    "\n",
    "    out_count = {}\n",
    "    out_idx = []\n",
    "\n",
    "    #온도\n",
    "    temp = df[df['기온(°C)'] < - 100].index.tolist()\n",
    "    out_idx.extend(temp)\n",
    "    out_count['기온(°C)'] = len(out_idx)\n",
    "    df.loc[temp,'기온(°C)'] = np.NaN\n",
    "\n",
    "    #습도\n",
    "    humid = df[df['습도(%)'] <= -999.9].index.tolist()\n",
    "    out_idx.extend(humid)\n",
    "    out_count['습도(%)'] = len(humid)\n",
    "    df.loc[humid,'습도(%)'] = np.NaN\n",
    "\n",
    "    out_idx = list(set(out_idx))\n",
    "    \n",
    "    return out_count, out_idx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_out(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7182151a",
   "metadata": {},
   "source": [
    "## Correlation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.rename(columns = {'위도_x':'위도_미세먼지','경도_x':'경도_미세먼지'}, inplace = True)\n",
    "data2.columns\n",
    "data2.rename(columns = {'위도_미세먼지' : 'lat_air', '경도_미세먼지' : 'lon_air','기상관측위도' : 'lat_weather',\n",
    "                      '기상관측경도' : 'lon_weather','기온(°C)':'temperature','강수량(mm)' : 'precipitation',\n",
    "                       '풍속(m/s)' : 'wind_speed','습도(%)':'humidity','풍향(deg)':'wind_direction'},inplace = True)\n",
    "\n",
    "col = ['PM10', 'SO2', 'CO', 'O3', 'NO2', 'lat_air', 'lon_air',\n",
    "       'lat_weather', 'lon_weather', 'temperature', 'precipitation',\n",
    "       'wind_speed', 'wind_direction', 'humidity']\n",
    "cor_dict = {'Variable' : ['SO2', 'CO', 'O3', 'NO2', 'lat_air', 'lon_air', 'lat_weather',\n",
    "       'lon_weather', 'temperature', 'precipitation', 'wind_speed',\n",
    "       'wind_direction', 'humidity'],\n",
    "           'Correlation value' : [0.27423588695628665, 0.35496693047554745, -0.02369964881321885,\n",
    "       0.33152344997678673, 0.09084290666082527, -0.056391897151533456,\n",
    "       0.0906610613277951, -0.05548579820320683, -0.10822153530423906,\n",
    "       -0.07090482791143295, -0.03533185904073229, 0.03171530421690104,\n",
    "       -0.1597643906655796]}\n",
    "\n",
    "cor_df = pd.DataFrame(cor_dict)\n",
    "cor_df.sort_values(by = 'Correlation value',inplace = True,ascending = False)\n",
    "plt.figure(figsize = (13,8))\n",
    "sns.barplot(data=cor_df,y = 'Variable',x = 'Correlation value')\n",
    "#plt.xticks(rotation = 90)\n",
    "plt.ylabel('Variable', fontsize = 13)\n",
    "plt.xlabel('Correlation Coefficient', fontsize = 13)\n",
    "plt.savefig('correlation graph.png',dpi =200)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(data = data[col].corr(), annot=True, fmt = '.2f', linewidths=.5, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb9bc3a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4c13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = np.load('data/train_final.npy')\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_final[:,1:], train_final[:,0], test_size=0.2,random_state = 42)\n",
    "x_train.shape, x_valid.shape\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],1,x_train.shape[1])\n",
    "x_valid = x_valid.reshape(x_valid.shape[0],1,x_valid.shape[1])\n",
    "\n",
    "print(x_train.shape, x_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116926d3",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06adcb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(16, \n",
    "               input_shape=(x_train.shape[1], x_train.shape[2]), \n",
    "               activation='relu', \n",
    "               return_sequences=False)\n",
    "          )\n",
    "\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7900a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "device_name = \"/device:GPU:\" + '0'\n",
    "\n",
    "with tf.device(device_name):\n",
    "    start_time = time.time()\n",
    "    print('Start')\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    model_path = 'LSTM_trial1'\n",
    "    filename = os.path.join(model_path, 'tmp_checkpoint.h5')\n",
    "    checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "    history = model.fit(x_train, y_train, \n",
    "                    epochs=20, \n",
    "                    validation_data=(x_valid, y_valid), \n",
    "                    callbacks=[early_stop, checkpoint])\n",
    "    \n",
    "    print('End')\n",
    "    print(\"Time: {:.4f}sec\".format((time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e5d73",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d4152",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred = model.predict(test_feature)\n",
    "\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341cbf97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyerim_py36",
   "language": "python",
   "name": "hyerim_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
